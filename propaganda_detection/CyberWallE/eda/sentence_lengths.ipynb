{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence_lengths.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:env]",
      "language": "python",
      "name": "conda-env-env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMe5WiWGwIxh",
        "colab_type": "text"
      },
      "source": [
        "Inspecting the sentence and span lengths in the data to see correlation between propaganda techniques and span lengths and to decide on a maximum sentence lengths for our systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZLiherWr0hr",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "TC_LABELS_FILE = '../data/tc-train.tsv'\n",
        "SI_LABELS_FILE = '../data/train-data-with-sents-no-maxlen.tsv'\n",
        "SI_LABELS_FILE_BASELINE = '../data/train-data-with-sents-baseline.tsv'\n",
        "SI_LABELS_FILE_IMPROVED = '../data/train-data-with-sents-improved.tsv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kbij3hjcr0h4"
      },
      "source": [
        "# Technique Classification (span length)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "566BF4upr0h5",
        "outputId": "4decd684-77b9-4487-f7c2-e024d2aa9c65",
        "colab": {}
      },
      "source": [
        "# quoting=3 --> 'treat quotes as normal characters'\n",
        "df = pd.read_csv(TC_LABELS_FILE, sep='\\t',\n",
        "                 usecols=['document_id', 'label', 'span_start', 'span_end', 'text'],\n",
        "                 encoding='ISO-8859-1', quoting=3)\n",
        "df['length_words'] = df['text'].apply(lambda x : len(str(x).split()))\n",
        "df['length_chars'] = df['span_end'] - df['span_start']\n",
        "df.groupby(['label']).length_words.describe().sort_values('mean', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Appeal_to_Authority</th>\n",
              "      <td>144.0</td>\n",
              "      <td>23.201389</td>\n",
              "      <td>21.854119</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>29.25</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Causal_Oversimplification</th>\n",
              "      <td>209.0</td>\n",
              "      <td>21.521531</td>\n",
              "      <td>12.616792</td>\n",
              "      <td>3.0</td>\n",
              "      <td>13.00</td>\n",
              "      <td>19.0</td>\n",
              "      <td>28.00</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doubt</th>\n",
              "      <td>493.0</td>\n",
              "      <td>21.144016</td>\n",
              "      <td>16.127337</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>17.0</td>\n",
              "      <td>29.00</td>\n",
              "      <td>141.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Black-and-White_Fallacy</th>\n",
              "      <td>107.0</td>\n",
              "      <td>18.710280</td>\n",
              "      <td>13.242306</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.00</td>\n",
              "      <td>16.0</td>\n",
              "      <td>23.00</td>\n",
              "      <td>58.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Appeal_to_fear-prejudice</th>\n",
              "      <td>294.0</td>\n",
              "      <td>17.047619</td>\n",
              "      <td>12.905449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>13.5</td>\n",
              "      <td>25.00</td>\n",
              "      <td>74.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
              "      <td>108.0</td>\n",
              "      <td>16.500000</td>\n",
              "      <td>11.353702</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>22.25</td>\n",
              "      <td>71.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
              "      <td>72.0</td>\n",
              "      <td>16.444444</td>\n",
              "      <td>12.281773</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.00</td>\n",
              "      <td>60.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Flag-Waving</th>\n",
              "      <td>229.0</td>\n",
              "      <td>10.628821</td>\n",
              "      <td>11.630165</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>15.00</td>\n",
              "      <td>73.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exaggeration,Minimisation</th>\n",
              "      <td>466.0</td>\n",
              "      <td>7.442060</td>\n",
              "      <td>5.824851</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thought-terminating_Cliches</th>\n",
              "      <td>76.0</td>\n",
              "      <td>6.131579</td>\n",
              "      <td>4.024399</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Slogans</th>\n",
              "      <td>129.0</td>\n",
              "      <td>4.325581</td>\n",
              "      <td>2.568325</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Name_Calling,Labeling</th>\n",
              "      <td>1058.0</td>\n",
              "      <td>3.932892</td>\n",
              "      <td>3.314233</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Loaded_Language</th>\n",
              "      <td>2123.0</td>\n",
              "      <td>3.818653</td>\n",
              "      <td>4.493748</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Repetition</th>\n",
              "      <td>621.0</td>\n",
              "      <td>2.813205</td>\n",
              "      <td>3.453454</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     count       mean        std  min    25%  \\\n",
              "label                                                                          \n",
              "Appeal_to_Authority                 144.0   23.201389  21.854119  2.0  10.00   \n",
              "Causal_Oversimplification           209.0   21.521531  12.616792  3.0  13.00   \n",
              "Doubt                               493.0   21.144016  16.127337  1.0  9.00    \n",
              "Black-and-White_Fallacy             107.0   18.710280  13.242306  2.0  9.00    \n",
              "Appeal_to_fear-prejudice            294.0   17.047619  12.905449  1.0  6.00    \n",
              "Whataboutism,Straw_Men,Red_Herring  108.0   16.500000  11.353702  1.0  8.00    \n",
              "Bandwagon,Reductio_ad_hitlerum      72.0    16.444444  12.281773  2.0  7.00    \n",
              "Flag-Waving                         229.0   10.628821  11.630165  1.0  2.00    \n",
              "Exaggeration,Minimisation           466.0   7.442060   5.824851   1.0  3.00    \n",
              "Thought-terminating_Cliches         76.0    6.131579   4.024399   1.0  3.75    \n",
              "Slogans                             129.0   4.325581   2.568325   1.0  3.00    \n",
              "Name_Calling,Labeling               1058.0  3.932892   3.314233   1.0  2.00    \n",
              "Loaded_Language                     2123.0  3.818653   4.493748   1.0  2.00    \n",
              "Repetition                          621.0   2.813205   3.453454   1.0  1.00    \n",
              "\n",
              "                                     50%    75%    max  \n",
              "label                                                   \n",
              "Appeal_to_Authority                 16.0  29.25  130.0  \n",
              "Causal_Oversimplification           19.0  28.00  71.0   \n",
              "Doubt                               17.0  29.00  141.0  \n",
              "Black-and-White_Fallacy             16.0  23.00  58.0   \n",
              "Appeal_to_fear-prejudice            13.5  25.00  74.0   \n",
              "Whataboutism,Straw_Men,Red_Herring  15.0  22.25  71.0   \n",
              "Bandwagon,Reductio_ad_hitlerum      13.0  21.00  60.0   \n",
              "Flag-Waving                         6.0   15.00  73.0   \n",
              "Exaggeration,Minimisation           6.0   10.00  43.0   \n",
              "Thought-terminating_Cliches         5.0   8.00   20.0   \n",
              "Slogans                             4.0   5.00   15.0   \n",
              "Name_Calling,Labeling               3.0   5.00   28.0   \n",
              "Loaded_Language                     3.0   5.00   90.0   \n",
              "Repetition                          2.0   3.00   31.0   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYM9PM6YwIx-",
        "colab_type": "text"
      },
      "source": [
        "Long sequences tend to consist of multiple connected sentences and/or quotes with somewhat arbitrary cut-off points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZE80ZtMVr0iN",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "df[df.length_words > 60][['label', 'sent']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iXt4yeiNr0iX"
      },
      "source": [
        "# Span Identification (sentence length)\n",
        "\n",
        "## Sentences as split by NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AX-7Kiozr0iZ",
        "colab": {}
      },
      "source": [
        "# The quoting=3 part is really important!\n",
        "\n",
        "df = pd.read_csv(SI_LABELS_FILE, sep='\\t', names=['doc_id', 'sent_id', 'idx_start', 'idx_end', 'tokens', 'label'], encoding='utf-8', quoting=3)\n",
        "df = df.drop(columns=['doc_id', 'idx_start', 'idx_end', 'label'])\n",
        "df = df.groupby('sent_id')['tokens'].apply(list).to_frame()\n",
        "df['sent_len'] = df['tokens'].apply(lambda x : len(x))\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "df.head(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ptc5wvGtr0if"
      },
      "source": [
        "## Baseline\n",
        "Sentences split into fragments if they are longer than 35 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WDsStHATr0ig",
        "colab": {}
      },
      "source": [
        "df_baseline = pd.read_csv(SI_LABELS_FILE_BASELINE, sep='\\t', names=['doc_id', 'sent_id', 'idx_start', 'idx_end', 'tokens', 'label'], encoding='utf-8', quoting=3)\n",
        "df_baseline = df_baseline.drop(columns=['doc_id', 'idx_start', 'idx_end', 'label'])\n",
        "df_baseline = df_baseline.groupby('sent_id')['tokens'].apply(list).to_frame()\n",
        "df_baseline['sent_len'] = df_baseline['tokens'].apply(lambda x : len(x))\n",
        "df_baseline.head(18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MbvtPLkhr0in"
      },
      "source": [
        "## Improved splitting\n",
        "\n",
        "- NLTK sentence splitter\n",
        "- Always split along linebreaks\n",
        "- If a sentence is too long: split along quotes, semicolons, colons, commas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LuDxy-VUr0io",
        "colab": {}
      },
      "source": [
        "df_improved = pd.read_csv(SI_LABELS_FILE_IMPROVED, sep='\\t', names=['doc_id', 'sent_id', 'idx_start', 'idx_end', 'tokens', 'label'], encoding='utf-8', quoting=3)\n",
        "df_improved = df_improved.drop(columns=['doc_id', 'idx_start', 'idx_end', 'label'])\n",
        "df_improved = df_improved.groupby('sent_id')['tokens'].apply(list).to_frame()\n",
        "df_improved['sent_len'] = df_improved['tokens'].apply(lambda x : len(x))\n",
        "df_improved.head(19)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjuhJe1Ur0it",
        "colab": {}
      },
      "source": [
        "pd.concat([df.describe(), df_baseline.describe(), df_improved.describe()], axis=1, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6v9A8igKr0i6"
      },
      "source": [
        "- Punctuation marks add a lot of tokens to a sentence!\n",
        "- Embedded quotes can be a problem\n",
        "- Headlines w/o punctuation are recognized as part of the following sentence\n",
        "- Some sentences are just very long (writing style)\n",
        "\n",
        "Abbreviations are the opposite problem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBu5pT3Pr0i8",
        "colab": {}
      },
      "source": [
        "df_improved[df_improved.sent_len == 1][['sent_len', 'tokens']]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}