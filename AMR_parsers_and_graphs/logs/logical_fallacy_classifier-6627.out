/cluster/raid/home/zhivar.sourati/logical-fallacy-identification/AMR_parsers_and_graphs
Mon Oct  3 09:50:10 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:28:00.0 Off |                    0 |
| N/A   60C    P0   235W / 250W |   1824MiB / 40536MiB |     59%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A   2420754      C   ...r/miniconda/bin/python3.8     1821MiB |
+-----------------------------------------------------------------------------+
0
base model using the masked version of the sentences
cuda
using GPU
Model loaded!
Start the training ...
{'loss': 2.5153, 'learning_rate': 1.913793103448276e-05, 'epoch': 0.22}
{'eval_loss': 2.400555372238159, 'eval_accuracy': 0.20333333333333334, 'eval_f1': 0.06871652816251154, 'eval_precision': 0.04134444444444445, 'eval_recall': 0.20333333333333334, 'eval_runtime': 0.346, 'eval_samples_per_second': 866.93, 'eval_steps_per_second': 109.811, 'epoch': 0.22}
{'loss': 2.4411, 'learning_rate': 1.827586206896552e-05, 'epoch': 0.43}
{'eval_loss': 2.2849819660186768, 'eval_accuracy': 0.20333333333333334, 'eval_f1': 0.06871652816251154, 'eval_precision': 0.04134444444444445, 'eval_recall': 0.20333333333333334, 'eval_runtime': 0.3335, 'eval_samples_per_second': 899.473, 'eval_steps_per_second': 113.933, 'epoch': 0.43}
{'loss': 2.2531, 'learning_rate': 1.7413793103448276e-05, 'epoch': 0.65}
{'eval_loss': 2.0181868076324463, 'eval_accuracy': 0.4066666666666667, 'eval_f1': 0.33602876193045167, 'eval_precision': 0.3664920052388407, 'eval_recall': 0.4066666666666667, 'eval_runtime': 0.3317, 'eval_samples_per_second': 904.537, 'eval_steps_per_second': 114.575, 'epoch': 0.65}
{'loss': 2.1437, 'learning_rate': 1.6551724137931037e-05, 'epoch': 0.86}
{'eval_loss': 1.875216007232666, 'eval_accuracy': 0.4533333333333333, 'eval_f1': 0.4158669083299366, 'eval_precision': 0.43440846255196114, 'eval_recall': 0.4533333333333333, 'eval_runtime': 0.3312, 'eval_samples_per_second': 905.89, 'eval_steps_per_second': 114.746, 'epoch': 0.86}
{'loss': 1.8329, 'learning_rate': 1.5689655172413794e-05, 'epoch': 1.08}
{'eval_loss': 1.6640876531600952, 'eval_accuracy': 0.5066666666666667, 'eval_f1': 0.46902043906676333, 'eval_precision': 0.48110404185817507, 'eval_recall': 0.5066666666666667, 'eval_runtime': 0.3659, 'eval_samples_per_second': 820.003, 'eval_steps_per_second': 103.867, 'epoch': 1.08}
{'loss': 1.5928, 'learning_rate': 1.4827586206896554e-05, 'epoch': 1.29}
{'eval_loss': 1.559807538986206, 'eval_accuracy': 0.5666666666666667, 'eval_f1': 0.5454062673936172, 'eval_precision': 0.5698631928957334, 'eval_recall': 0.5666666666666667, 'eval_runtime': 0.3297, 'eval_samples_per_second': 909.812, 'eval_steps_per_second': 115.243, 'epoch': 1.29}
{'loss': 1.6196, 'learning_rate': 1.3965517241379311e-05, 'epoch': 1.51}
{'eval_loss': 1.4991674423217773, 'eval_accuracy': 0.5566666666666666, 'eval_f1': 0.5407930726286383, 'eval_precision': 0.6072739413364413, 'eval_recall': 0.5566666666666666, 'eval_runtime': 0.3303, 'eval_samples_per_second': 908.15, 'eval_steps_per_second': 115.032, 'epoch': 1.51}
{'loss': 1.4306, 'learning_rate': 1.310344827586207e-05, 'epoch': 1.72}
{'eval_loss': 1.3811380863189697, 'eval_accuracy': 0.5766666666666667, 'eval_f1': 0.5647238805295949, 'eval_precision': 0.5826438482628954, 'eval_recall': 0.5766666666666667, 'eval_runtime': 0.3298, 'eval_samples_per_second': 909.541, 'eval_steps_per_second': 115.208, 'epoch': 1.72}
{'loss': 1.4906, 'learning_rate': 1.2241379310344827e-05, 'epoch': 1.94}
{'eval_loss': 1.3152860403060913, 'eval_accuracy': 0.6133333333333333, 'eval_f1': 0.5981545926160486, 'eval_precision': 0.6292105118380981, 'eval_recall': 0.6133333333333333, 'eval_runtime': 0.3288, 'eval_samples_per_second': 912.407, 'eval_steps_per_second': 115.572, 'epoch': 1.94}
{'loss': 1.1651, 'learning_rate': 1.1379310344827587e-05, 'epoch': 2.16}
{'eval_loss': 1.2276380062103271, 'eval_accuracy': 0.6533333333333333, 'eval_f1': 0.6465053206492934, 'eval_precision': 0.6754730410112764, 'eval_recall': 0.6533333333333333, 'eval_runtime': 0.3279, 'eval_samples_per_second': 914.923, 'eval_steps_per_second': 115.89, 'epoch': 2.16}
{'loss': 0.9536, 'learning_rate': 1.0517241379310346e-05, 'epoch': 2.37}
{'eval_loss': 1.2288340330123901, 'eval_accuracy': 0.65, 'eval_f1': 0.6434312973050113, 'eval_precision': 0.6598181045533986, 'eval_recall': 0.65, 'eval_runtime': 0.3301, 'eval_samples_per_second': 908.875, 'eval_steps_per_second': 115.124, 'epoch': 2.37}
{'loss': 1.0257, 'learning_rate': 9.655172413793105e-06, 'epoch': 2.59}
{'eval_loss': 1.2330020666122437, 'eval_accuracy': 0.66, 'eval_f1': 0.6481818053804264, 'eval_precision': 0.6805246630079546, 'eval_recall': 0.66, 'eval_runtime': 0.3298, 'eval_samples_per_second': 909.549, 'eval_steps_per_second': 115.21, 'epoch': 2.59}
{'loss': 0.9763, 'learning_rate': 8.793103448275862e-06, 'epoch': 2.8}
{'eval_loss': 1.2238515615463257, 'eval_accuracy': 0.6433333333333333, 'eval_f1': 0.637959767714305, 'eval_precision': 0.6573604778434499, 'eval_recall': 0.6433333333333333, 'eval_runtime': 0.3297, 'eval_samples_per_second': 909.894, 'eval_steps_per_second': 115.253, 'epoch': 2.8}
{'loss': 1.0182, 'learning_rate': 7.93103448275862e-06, 'epoch': 3.02}
{'eval_loss': 1.1894665956497192, 'eval_accuracy': 0.6466666666666666, 'eval_f1': 0.6478086775291672, 'eval_precision': 0.6663413364669993, 'eval_recall': 0.6466666666666666, 'eval_runtime': 0.3306, 'eval_samples_per_second': 907.485, 'eval_steps_per_second': 114.948, 'epoch': 3.02}
{'loss': 0.7064, 'learning_rate': 7.0689655172413796e-06, 'epoch': 3.23}
{'eval_loss': 1.1745740175247192, 'eval_accuracy': 0.6633333333333333, 'eval_f1': 0.6543417360725902, 'eval_precision': 0.6612635587926285, 'eval_recall': 0.6633333333333333, 'eval_runtime': 0.3302, 'eval_samples_per_second': 908.475, 'eval_steps_per_second': 115.073, 'epoch': 3.23}
{'loss': 0.6922, 'learning_rate': 6.206896551724138e-06, 'epoch': 3.45}
{'eval_loss': 1.174561619758606, 'eval_accuracy': 0.6466666666666666, 'eval_f1': 0.6453440566984916, 'eval_precision': 0.6635417560235102, 'eval_recall': 0.6466666666666666, 'eval_runtime': 0.3302, 'eval_samples_per_second': 908.55, 'eval_steps_per_second': 115.083, 'epoch': 3.45}
{'loss': 0.6576, 'learning_rate': 5.344827586206896e-06, 'epoch': 3.66}
{'eval_loss': 1.1447372436523438, 'eval_accuracy': 0.6833333333333333, 'eval_f1': 0.6753471478137661, 'eval_precision': 0.6851952026468155, 'eval_recall': 0.6833333333333333, 'eval_runtime': 0.3312, 'eval_samples_per_second': 905.844, 'eval_steps_per_second': 114.74, 'epoch': 3.66}
{'loss': 0.6954, 'learning_rate': 4.482758620689656e-06, 'epoch': 3.88}
{'eval_loss': 1.1486992835998535, 'eval_accuracy': 0.67, 'eval_f1': 0.6673527183901904, 'eval_precision': 0.6792406312219774, 'eval_recall': 0.67, 'eval_runtime': 0.3702, 'eval_samples_per_second': 810.468, 'eval_steps_per_second': 102.659, 'epoch': 3.88}
{'loss': 0.6398, 'learning_rate': 3.620689655172414e-06, 'epoch': 4.09}
{'eval_loss': 1.1301785707473755, 'eval_accuracy': 0.6833333333333333, 'eval_f1': 0.6762028739514018, 'eval_precision': 0.6835114175260646, 'eval_recall': 0.6833333333333333, 'eval_runtime': 0.3292, 'eval_samples_per_second': 911.2, 'eval_steps_per_second': 115.419, 'epoch': 4.09}
{'loss': 0.5015, 'learning_rate': 2.7586206896551725e-06, 'epoch': 4.31}
{'eval_loss': 1.1283621788024902, 'eval_accuracy': 0.68, 'eval_f1': 0.6735109922764436, 'eval_precision': 0.6749890301758125, 'eval_recall': 0.68, 'eval_runtime': 0.3304, 'eval_samples_per_second': 907.993, 'eval_steps_per_second': 115.012, 'epoch': 4.31}
{'loss': 0.4761, 'learning_rate': 1.896551724137931e-06, 'epoch': 4.53}
{'eval_loss': 1.1479531526565552, 'eval_accuracy': 0.6766666666666666, 'eval_f1': 0.6708760990699267, 'eval_precision': 0.6761622795363204, 'eval_recall': 0.6766666666666666, 'eval_runtime': 0.3324, 'eval_samples_per_second': 902.503, 'eval_steps_per_second': 114.317, 'epoch': 4.53}
{'loss': 0.5349, 'learning_rate': 1.0344827586206898e-06, 'epoch': 4.74}
{'eval_loss': 1.1517821550369263, 'eval_accuracy': 0.7, 'eval_f1': 0.6940910969265519, 'eval_precision': 0.7025903527302394, 'eval_recall': 0.7, 'eval_runtime': 0.3322, 'eval_samples_per_second': 903.088, 'eval_steps_per_second': 114.391, 'epoch': 4.74}
{'loss': 0.4836, 'learning_rate': 1.7241379310344828e-07, 'epoch': 4.96}
{'eval_loss': 1.1542845964431763, 'eval_accuracy': 0.6866666666666666, 'eval_f1': 0.681085222795308, 'eval_precision': 0.6896828506595867, 'eval_recall': 0.6866666666666666, 'eval_runtime': 0.3317, 'eval_samples_per_second': 904.498, 'eval_steps_per_second': 114.57, 'epoch': 4.96}
{'train_runtime': 90.8326, 'train_samples_per_second': 101.781, 'train_steps_per_second': 12.771, 'train_loss': 1.203372323513031, 'epoch': 5.0}
performance on train data
                        precision    recall  f1-score   support

            ad hominem       0.96      0.98      0.97       225
            ad populum       0.96      0.94      0.95       158
     appeal to emotion       0.92      0.93      0.92       130
    circular reasoning       0.86      0.93      0.89       134
          equivocation       0.00      0.00      0.00        39
fallacy of credibility       0.85      0.92      0.88       107
  fallacy of extension       0.93      0.92      0.93       106
      fallacy of logic       0.82      0.88      0.85       121
  fallacy of relevance       0.89      0.86      0.88       114
       false causality       0.94      0.97      0.95       174
         false dilemma       0.93      0.96      0.95       110
 faulty generalization       0.98      0.94      0.96       319
           intentional       0.87      0.96      0.91       112

              accuracy                           0.92      1849
             macro avg       0.84      0.86      0.85      1849
          weighted avg       0.90      0.92      0.91      1849

performance on train data
                        precision    recall  f1-score   support

            ad hominem       0.74      0.86      0.79        36
            ad populum       0.73      0.82      0.77        44
     appeal to emotion       0.67      0.71      0.69        14
    circular reasoning       0.56      0.78      0.65        18
          equivocation       0.00      0.00      0.00         5
fallacy of credibility       0.38      0.62      0.48         8
  fallacy of extension       0.54      0.50      0.52        14
      fallacy of logic       0.63      0.71      0.67        17
  fallacy of relevance       0.73      0.46      0.56        24
       false causality       0.73      0.67      0.70        24
         false dilemma       0.88      0.79      0.83        19
 faulty generalization       0.78      0.66      0.71        61
           intentional       0.47      0.56      0.51        16

              accuracy                           0.69       300
             macro avg       0.60      0.63      0.61       300
          weighted avg       0.69      0.69      0.68       300

performance on train data
                        precision    recall  f1-score   support

            ad hominem       0.73      0.88      0.80        41
            ad populum       0.65      0.80      0.72        30
     appeal to emotion       0.73      0.48      0.58        23
    circular reasoning       0.52      0.58      0.55        19
          equivocation       0.00      0.00      0.00         5
fallacy of credibility       0.35      0.41      0.38        17
  fallacy of extension       0.67      0.48      0.56        21
      fallacy of logic       0.50      0.50      0.50        14
  fallacy of relevance       0.73      0.33      0.46        24
       false causality       0.53      0.56      0.54        18
         false dilemma       0.73      0.92      0.81        12
 faulty generalization       0.67      0.67      0.67        61
           intentional       0.26      0.40      0.32        15

              accuracy                           0.61       300
             macro avg       0.54      0.54      0.53       300
          weighted avg       0.61      0.61      0.60       300

case based reasoning with 1 cases and simcse similarity
cuda
