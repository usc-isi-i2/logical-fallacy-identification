/cluster/raid/home/zhivar.sourati/logical-fallacy-identification/AMR_parsers_and_graphs
Tue Sep 27 08:59:40 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  A100-PCIE-40GB      Off  | 00000000:27:00.0 Off |                    0 |
| N/A   32C    P0    33W / 250W |      0MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
0
cuda
using GPU
doing the case augmentation ...
                        precision    recall  f1-score   support

            ad hominem       0.99      0.99      0.99       225
            ad populum       0.96      0.99      0.98       158
     appeal to emotion       1.00      0.96      0.98       130
    circular reasoning       0.99      0.99      0.99       134
          equivocation       0.90      0.92      0.91        39
fallacy of credibility       0.98      0.99      0.99       107
  fallacy of extension       1.00      0.97      0.99       106
      fallacy of logic       0.95      0.99      0.97       121
  fallacy of relevance       1.00      0.99      1.00       114
       false causality       1.00      0.95      0.98       174
         false dilemma       0.99      1.00      1.00       110
 faulty generalization       0.98      1.00      0.99       319
           intentional       0.99      0.97      0.98       112

              accuracy                           0.98      1849
             macro avg       0.98      0.98      0.98      1849
          weighted avg       0.98      0.98      0.98      1849

Number of data points augmented with high confidence: 0.9643050297458086
Error finding the predicted label for sentence: " Just like students are given a couple of MSK0 of MSK3 before taking exams , MSK1 should also be given few days or MSK0 to MSK3 MSK1 before an operation or MSK2 , after all MSK2 is not as easy task " Is an example of .... 
Error finding the predicted label for sentence: " There MSK0 was in the MSK1 of MSK2 , and yet a perfect stranger ; without home and without friends , in the MSK1 of thousands of MSK0 own brethren â€” children of a common Father , and yet MSK0 dared not to unfold to any one of MSK2 MSK0 sad condition . " Check each literary term found in this quote : 
                        precision    recall  f1-score   support

            ad hominem       0.49      0.47      0.48        36
            ad populum       0.61      0.52      0.56        44
     appeal to emotion       0.25      0.15      0.19        13
    circular reasoning       0.48      0.56      0.51        18
          equivocation       0.33      0.60      0.43         5
fallacy of credibility       0.06      0.12      0.08         8
  fallacy of extension       0.60      0.21      0.32        14
      fallacy of logic       0.43      0.35      0.39        17
  fallacy of relevance       0.25      0.17      0.20        24
       false causality       0.50      0.42      0.45        24
         false dilemma       0.68      0.68      0.68        19
 faulty generalization       0.43      0.61      0.50        61
           intentional       0.42      0.31      0.36        16

              accuracy                           0.45       299
             macro avg       0.42      0.40      0.40       299
          weighted avg       0.46      0.45      0.44       299

Number of data points augmented with high confidence: 0.75
Error finding the predicted label for sentence: MSK0 call MSK1 yet MSK0 can not lend MSK2 money for MSK2 school project , murdering MSK2 chance for a higher grade . MSK0 are just like MSK1 . 
                        precision    recall  f1-score   support

            ad hominem       0.47      0.51      0.49        41
            ad populum       0.64      0.47      0.54        30
     appeal to emotion       0.54      0.30      0.39        23
    circular reasoning       0.19      0.32      0.24        19
          equivocation       0.00      0.00      0.00         5
fallacy of credibility       0.27      0.35      0.31        17
  fallacy of extension       0.80      0.38      0.52        21
      fallacy of logic       0.18      0.21      0.19        14
  fallacy of relevance       0.33      0.30      0.32        23
       false causality       0.40      0.11      0.17        18
         false dilemma       0.41      0.92      0.56        12
 faulty generalization       0.52      0.59      0.55        61
           intentional       0.50      0.47      0.48        15

              accuracy                           0.43       299
             macro avg       0.40      0.38      0.37       299
          weighted avg       0.46      0.43      0.42       299

Number of data points augmented with high confidence: 0.7433333333333333
Model loaded!
Start the training ...
{'loss': 2.5395, 'learning_rate': 9.461206896551725e-06, 'epoch': 0.43}
{'eval_loss': 2.44905161857605, 'eval_accuracy': 0.20469798657718122, 'eval_f1': 0.09796542778185101, 'eval_precision': 0.08593597021209677, 'eval_recall': 0.20469798657718122, 'eval_runtime': 2.2031, 'eval_samples_per_second': 135.263, 'eval_steps_per_second': 8.624, 'epoch': 0.43}
{'loss': 2.4984, 'learning_rate': 8.922413793103449e-06, 'epoch': 0.86}
{'eval_loss': 2.3742780685424805, 'eval_accuracy': 0.18120805369127516, 'eval_f1': 0.09607733897114079, 'eval_precision': 0.07738004233504882, 'eval_recall': 0.18120805369127516, 'eval_runtime': 2.2043, 'eval_samples_per_second': 135.192, 'eval_steps_per_second': 8.62, 'epoch': 0.86}
{'loss': 2.2258, 'learning_rate': 8.383620689655173e-06, 'epoch': 1.29}
{'eval_loss': 1.8351104259490967, 'eval_accuracy': 0.4395973154362416, 'eval_f1': 0.3562951213127555, 'eval_precision': 0.3878329007915191, 'eval_recall': 0.4395973154362416, 'eval_runtime': 2.2104, 'eval_samples_per_second': 134.82, 'eval_steps_per_second': 8.596, 'epoch': 1.29}
{'loss': 1.6454, 'learning_rate': 7.844827586206897e-06, 'epoch': 1.72}
{'eval_loss': 1.3540623188018799, 'eval_accuracy': 0.6711409395973155, 'eval_f1': 0.6527802238796924, 'eval_precision': 0.67451916387717, 'eval_recall': 0.6711409395973155, 'eval_runtime': 2.2146, 'eval_samples_per_second': 134.564, 'eval_steps_per_second': 8.58, 'epoch': 1.72}
{'loss': 1.1062, 'learning_rate': 7.306034482758622e-06, 'epoch': 2.16}
{'eval_loss': 1.1587272882461548, 'eval_accuracy': 0.7416107382550335, 'eval_f1': 0.7321277967096028, 'eval_precision': 0.7407033460435288, 'eval_recall': 0.7416107382550335, 'eval_runtime': 2.2232, 'eval_samples_per_second': 134.039, 'eval_steps_per_second': 8.546, 'epoch': 2.16}
{'loss': 0.6919, 'learning_rate': 6.767241379310346e-06, 'epoch': 2.59}
{'eval_loss': 1.2045109272003174, 'eval_accuracy': 0.7516778523489933, 'eval_f1': 0.7399548482552416, 'eval_precision': 0.7517283993395556, 'eval_recall': 0.7516778523489933, 'eval_runtime': 2.2292, 'eval_samples_per_second': 133.679, 'eval_steps_per_second': 8.523, 'epoch': 2.59}
{'loss': 0.5975, 'learning_rate': 6.228448275862069e-06, 'epoch': 3.02}
{'eval_loss': 1.2068803310394287, 'eval_accuracy': 0.7785234899328859, 'eval_f1': 0.7696901857390465, 'eval_precision': 0.7742222738468532, 'eval_recall': 0.7785234899328859, 'eval_runtime': 2.2298, 'eval_samples_per_second': 133.643, 'eval_steps_per_second': 8.521, 'epoch': 3.02}
{'loss': 0.3496, 'learning_rate': 5.689655172413794e-06, 'epoch': 3.45}
{'eval_loss': 1.2737690210342407, 'eval_accuracy': 0.7718120805369127, 'eval_f1': 0.7636904972501827, 'eval_precision': 0.7687110556016187, 'eval_recall': 0.7718120805369127, 'eval_runtime': 2.2273, 'eval_samples_per_second': 133.793, 'eval_steps_per_second': 8.53, 'epoch': 3.45}
{'loss': 0.3418, 'learning_rate': 5.150862068965518e-06, 'epoch': 3.88}
{'eval_loss': 1.3172541856765747, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.2309, 'eval_samples_per_second': 133.577, 'eval_steps_per_second': 8.517, 'epoch': 3.88}
{'loss': 0.2117, 'learning_rate': 4.612068965517242e-06, 'epoch': 4.31}
{'eval_loss': 1.360693097114563, 'eval_accuracy': 0.7785234899328859, 'eval_f1': 0.7751526701067597, 'eval_precision': 0.7894089153376854, 'eval_recall': 0.7785234899328859, 'eval_runtime': 2.23, 'eval_samples_per_second': 133.634, 'eval_steps_per_second': 8.52, 'epoch': 4.31}
{'loss': 0.1727, 'learning_rate': 4.073275862068966e-06, 'epoch': 4.74}
{'eval_loss': 1.4323501586914062, 'eval_accuracy': 0.7751677852348994, 'eval_f1': 0.7728988346595941, 'eval_precision': 0.7926363168513026, 'eval_recall': 0.7751677852348994, 'eval_runtime': 2.2119, 'eval_samples_per_second': 134.728, 'eval_steps_per_second': 8.59, 'epoch': 4.74}
{'loss': 0.1229, 'learning_rate': 3.5344827586206898e-06, 'epoch': 5.17}
{'eval_loss': 1.527402639389038, 'eval_accuracy': 0.7751677852348994, 'eval_f1': 0.7717473631179953, 'eval_precision': 0.7884380736572888, 'eval_recall': 0.7751677852348994, 'eval_runtime': 2.2236, 'eval_samples_per_second': 134.019, 'eval_steps_per_second': 8.545, 'epoch': 5.17}
{'loss': 0.0668, 'learning_rate': 2.9956896551724142e-06, 'epoch': 5.6}
{'eval_loss': 1.6077077388763428, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.2236, 'eval_samples_per_second': 134.016, 'eval_steps_per_second': 8.545, 'epoch': 5.6}
{'loss': 0.1037, 'learning_rate': 2.4568965517241382e-06, 'epoch': 6.03}
{'eval_loss': 1.6247388124465942, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.226, 'eval_samples_per_second': 133.871, 'eval_steps_per_second': 8.535, 'epoch': 6.03}
{'loss': 0.0546, 'learning_rate': 1.9181034482758622e-06, 'epoch': 6.47}
{'eval_loss': 1.6993927955627441, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.2342, 'eval_samples_per_second': 133.379, 'eval_steps_per_second': 8.504, 'epoch': 6.47}
{'loss': 0.0671, 'learning_rate': 1.3793103448275862e-06, 'epoch': 6.9}
{'eval_loss': 1.697234869003296, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.23, 'eval_samples_per_second': 133.63, 'eval_steps_per_second': 8.52, 'epoch': 6.9}
{'loss': 0.0462, 'learning_rate': 8.405172413793105e-07, 'epoch': 7.33}
{'eval_loss': 1.7249950170516968, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.2321, 'eval_samples_per_second': 133.508, 'eval_steps_per_second': 8.512, 'epoch': 7.33}
{'loss': 0.0298, 'learning_rate': 3.0172413793103453e-07, 'epoch': 7.76}
{'eval_loss': 1.7432312965393066, 'eval_accuracy': 0.7818791946308725, 'eval_f1': 0.7780865662487221, 'eval_precision': 0.792836552528246, 'eval_recall': 0.7818791946308725, 'eval_runtime': 2.2317, 'eval_samples_per_second': 133.529, 'eval_steps_per_second': 8.514, 'epoch': 7.76}
{'train_runtime': 277.2216, 'train_samples_per_second': 53.358, 'train_steps_per_second': 3.348, 'train_loss': 0.694757090945696, 'epoch': 8.0}
PredictionOutput(predictions=array([[ 0.27210626, -1.0891926 , -1.001795  , ..., -0.8500317 ,
        -0.65351146, -0.8016806 ],
       [-0.7519622 , -0.40721297, -0.32352072, ..., -0.26495057,
         8.269576  , -0.7147895 ],
       [-0.7339858 , -1.494942  , -1.5115199 , ..., -1.0421897 ,
         0.10354391, -1.1636204 ],
       ...,
       [ 0.14219216, -0.8223755 , -0.77800435, ..., -0.8364866 ,
        -0.7260804 , -0.44307277],
       [ 0.37570482, -1.0516342 , -1.0130916 , ..., -0.96540797,
        -0.7378773 , -0.39984563],
       [ 0.05021923, -0.8861172 , -0.7707849 , ..., -0.87847376,
        -0.7071304 , -0.46756044]], dtype=float32), label_ids=array([ 6, 11,  7,  9, 11,  6,  6, 11,  5,  3,  9, 11,  0,  1, 11, 12,  1,
        7,  0, 12,  3,  1,  8,  3,  6,  8,  0,  0, 11,  0, 11,  3,  3,  5,
        2,  8,  9,  1, 11,  1,  5, 12,  0, 12,  1,  2, 12,  0,  5,  7,  3,
       11,  2,  4,  8,  3, 12, 11, 11, 10,  7, 11,  0, 10, 12,  0,  1,  8,
       12,  5, 10,  5,  1,  8,  0, 12,  1,  7, 10, 12,  7,  7,  2,  0,  2,
       10, 11,  0,  6,  0, 10,  9,  5,  5,  0,  9,  1,  2,  9,  0,  2,  0,
        7, 11,  9,  6,  6,  9,  3, 12,  7, 11, 11, 11, 10,  2,  8,  9,  0,
        7,  3, 11, 11, 12,  8,  0,  4, 11,  5,  8, 11,  1,  5, 11,  7, 11,
        0, 11,  0, 11,  6,  0, 11, 11,  8, 11,  1,  8,  6,  5,  0, 11,  9,
        0,  1,  5,  0,  1,  8,  8,  0,  2, 11, 11,  0,  6,  5,  6, 11,  2,
        2,  7,  9, 11,  1, 11,  1,  8,  9,  8,  6,  3,  8, 10,  1,  2,  0,
       11, 11,  3,  8,  6,  2,  4,  1, 11, 11, 11, 11,  0, 11,  2,  1,  8,
        1,  9,  0,  1, 11,  1,  5,  1,  6,  5,  0,  8,  0,  1, 10, 11,  9,
        0, 11, 12,  2,  4,  0, 11,  2, 12,  2, 11,  7,  3,  2,  2,  8,  3,
        0,  2, 11,  8,  8,  9,  3, 11,  6, 11,  0,  3,  2,  8, 10, 12, 11,
        5, 10,  6,  9, 11,  6,  3,  1,  6,  3,  7, 11,  6,  2, 11,  4, 10,
        9,  2,  0, 11,  5,  1, 11,  6, 11,  9, 11,  0,  0,  0, 11, 11,  0,
        1, 11,  1,  0,  3,  1,  6,  1, 11,  3]), metrics={'test_loss': 1.8102810382843018, 'test_accuracy': 0.7725752508361204, 'test_f1': 0.7710707510553939, 'test_precision': 0.7760634845126971, 'test_recall': 0.7725752508361204, 'test_runtime': 2.2176, 'test_samples_per_second': 134.831, 'test_steps_per_second': 8.568})
