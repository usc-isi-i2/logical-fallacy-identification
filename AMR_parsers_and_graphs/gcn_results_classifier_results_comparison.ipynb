{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_results = pd.read_csv(\"gcn_results/gcn_predictions_test.csv\")\n",
    "main_classifier_results = pd.read_csv('main_classifier_results/main_classifier_predictions_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who drive big cars probably hate the en...</td>\n",
       "      <td>fallacy of extension</td>\n",
       "      <td>fallacy of extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSK0 ca n't jump . No , really , MSK0 ca n't !</td>\n",
       "      <td>intentional</td>\n",
       "      <td>faulty generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' Cotton and grain crops were lower this year ...</td>\n",
       "      <td>appeal to emotion</td>\n",
       "      <td>fallacy of logic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence            prediction  \\\n",
       "0  People who drive big cars probably hate the en...  fallacy of extension   \n",
       "1    MSK0 ca n't jump . No , really , MSK0 ca n't !            intentional   \n",
       "2  ' Cotton and grain crops were lower this year ...     appeal to emotion   \n",
       "\n",
       "              true_label  \n",
       "0   fallacy of extension  \n",
       "1  faulty generalization  \n",
       "2       fallacy of logic  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who drive big cars probably hate the en...</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>fallacy of extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSK0 ca n't jump . No , really , MSK0 ca n't !</td>\n",
       "      <td>intentional</td>\n",
       "      <td>faulty generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' Cotton and grain crops were lower this year ...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>fallacy of logic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence             prediction  \\\n",
       "0  People who drive big cars probably hate the en...  faulty generalization   \n",
       "1    MSK0 ca n't jump . No , really , MSK0 ca n't !             intentional   \n",
       "2  ' Cotton and grain crops were lower this year ...        false causality   \n",
       "\n",
       "              true_label  \n",
       "0   fallacy of extension  \n",
       "1  faulty generalization  \n",
       "2       fallacy of logic  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_classifier_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299, 3), (300, 3))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcn_results.shape, main_classifier_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_classifier_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = main_classifier_results.merge(on=['sentence', 'true_label'], right=gcn_results, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = all_results['true_label']\n",
    "main_predictions = all_results['prediction_x']\n",
    "gcn_predictions = all_results['prediction_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6211195371872518, 0.627906976744186)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=all_labels, y_pred=main_predictions, average =\"weighted\"), accuracy_score(y_true=all_labels, y_pred=main_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38127520702288065, 0.3787375415282392)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=all_labels, y_pred=gcn_predictions, average =\"weighted\"), accuracy_score(y_true=all_labels, y_pred=gcn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>prediction_x</th>\n",
       "      <th>true_label</th>\n",
       "      <th>prediction_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who drive big cars probably hate the en...</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>fallacy of extension</td>\n",
       "      <td>fallacy of extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSK0 ca n't jump . No , really , MSK0 ca n't !</td>\n",
       "      <td>intentional</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>intentional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>' Cotton and grain crops were lower this year ...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>appeal to emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" Why are MSK0 MSK1 MSK0 !? \" \" The last time ...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>false causality</td>\n",
       "      <td>circular reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All students are good and all clowns are bad .</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>faulty generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>An influencer posts on Instagram that the rest...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>faulty generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>MSK0 says MSK1 should cut back the Defense bud...</td>\n",
       "      <td>fallacy of extension</td>\n",
       "      <td>fallacy of extension</td>\n",
       "      <td>fallacy of extension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Going to prom ( when MSK0 do n't want to ) bec...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>ad populum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>While jogging around the neighborhood , you ar...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>faulty generalization</td>\n",
       "      <td>faulty generalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>MSK0 It ’s important to argue MSK1 because MSK...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>circular reasoning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>301 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence           prediction_x  \\\n",
       "0    People who drive big cars probably hate the en...  faulty generalization   \n",
       "1      MSK0 ca n't jump . No , really , MSK0 ca n't !             intentional   \n",
       "2    ' Cotton and grain crops were lower this year ...        false causality   \n",
       "3    \" Why are MSK0 MSK1 MSK0 !? \" \" The last time ...        false causality   \n",
       "4      All students are good and all clowns are bad .   faulty generalization   \n",
       "..                                                 ...                    ...   \n",
       "296  An influencer posts on Instagram that the rest...             ad populum   \n",
       "297  MSK0 says MSK1 should cut back the Defense bud...   fallacy of extension   \n",
       "298  Going to prom ( when MSK0 do n't want to ) bec...             ad populum   \n",
       "299  While jogging around the neighborhood , you ar...        false causality   \n",
       "300  MSK0 It ’s important to argue MSK1 because MSK...     circular reasoning   \n",
       "\n",
       "                true_label           prediction_y  \n",
       "0     fallacy of extension   fallacy of extension  \n",
       "1    faulty generalization            intentional  \n",
       "2         fallacy of logic      appeal to emotion  \n",
       "3          false causality     circular reasoning  \n",
       "4    faulty generalization  faulty generalization  \n",
       "..                     ...                    ...  \n",
       "296             ad populum  faulty generalization  \n",
       "297   fallacy of extension   fallacy of extension  \n",
       "298             ad populum             ad populum  \n",
       "299  faulty generalization  faulty generalization  \n",
       "300     circular reasoning     circular reasoning  \n",
       "\n",
       "[301 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['agg'] = all_results.apply(lambda x: x['prediction_x'] if x['prediction_x'] == x['true_label'] else x['prediction_y'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prediction = all_results['agg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            ad hominem       0.72      0.83      0.77        41\n",
      "            ad populum       0.85      0.77      0.81        30\n",
      "     appeal to emotion       0.72      0.57      0.63        23\n",
      "    circular reasoning       0.69      0.58      0.63        19\n",
      "          equivocation       0.00      0.00      0.00         5\n",
      "fallacy of credibility       0.58      0.65      0.61        17\n",
      "  fallacy of extension       0.53      0.48      0.50        21\n",
      "      fallacy of logic       0.50      0.50      0.50        14\n",
      "  fallacy of relevance       0.42      0.44      0.43        25\n",
      "       false causality       0.55      0.61      0.58        18\n",
      "         false dilemma       0.65      0.92      0.76        12\n",
      " faulty generalization       0.65      0.67      0.66        61\n",
      "           intentional       0.40      0.40      0.40        15\n",
      "\n",
      "              accuracy                           0.63       301\n",
      "             macro avg       0.56      0.57      0.56       301\n",
      "          weighted avg       0.62      0.63      0.62       301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = all_labels, y_pred=main_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "            ad hominem       0.75      0.88      0.81        41\n",
      "            ad populum       0.86      0.80      0.83        30\n",
      "     appeal to emotion       0.58      0.61      0.60        23\n",
      "    circular reasoning       0.44      0.74      0.55        19\n",
      "          equivocation       0.00      0.00      0.00         5\n",
      "fallacy of credibility       0.92      0.71      0.80        17\n",
      "  fallacy of extension       0.85      0.52      0.65        21\n",
      "      fallacy of logic       0.54      0.50      0.52        14\n",
      "  fallacy of relevance       0.68      0.52      0.59        25\n",
      "       false causality       0.75      0.67      0.71        18\n",
      "         false dilemma       0.55      0.92      0.69        12\n",
      " faulty generalization       0.73      0.77      0.75        61\n",
      "           intentional       0.55      0.40      0.46        15\n",
      "\n",
      "              accuracy                           0.69       301\n",
      "             macro avg       0.63      0.62      0.61       301\n",
      "          weighted avg       0.70      0.69      0.68       301\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/cluster/raid/home/zhivar.sourati/anaconda3/envs/general/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = all_labels, y_pred=agg_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('general': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67db27fda20c3469892b63d0da2b9ea8ebefbe65ab5f07c46b1a9548ed206d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
