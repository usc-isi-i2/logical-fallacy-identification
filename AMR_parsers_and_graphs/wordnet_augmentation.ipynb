{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from consts import PATH_TO_MASKED_SENTENCES_AMRS_\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_with_amr_container = joblib.load(PATH_TO_MASKED_SENTENCES_AMRS_WITH_LABEL2WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = sentences_with_amr_container[0]\n",
    "graph = obj[1].graph_nx\n",
    "label2words = obj[1].label2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['slogan', 'company', 'and', 'expect', 'more', 'pay', 'less'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2words.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "more = wn.synsets('more')[0]\n",
    "less = wn.synsets('less')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_synsets(word):\n",
    "    synonyms = []\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "    return set(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_antonyms(word):\n",
    "    antonyms = []\n",
    "    for syn in wn.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            for ant in lemma.antonyms():\n",
    "                antonyms.append(ant.name())\n",
    "    return set(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_words_are_antonyms(word1, word2):\n",
    "    word1_ants = find_antonyms(word1)\n",
    "    word2_ants = find_antonyms(word2)\n",
    "    return word1 in word2_ants or word2 in word1_ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_words_are_synonyms(word1, word2):\n",
    "    word1_syns = find_synsets(word1)\n",
    "    word2_syns = find_synsets(word2)\n",
    "    return word1 in word2_syns or word2 in word1_syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms_to_root(word):\n",
    "    hypernyms = []\n",
    "    for syn in wn.synsets(word):\n",
    "        for entity in syn.hypernym_paths()[0]:\n",
    "            for lemma in entity.lemmas():\n",
    "                hypernyms.append(lemma.name())\n",
    "    return set(hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypernyms_in_width_and_depth(word, level = 0):\n",
    "    all_hypernyms = []\n",
    "    hypernyms_in_queue = [(word, 0)]\n",
    "    processed_nodes = []\n",
    "    while len(hypernyms_in_queue):\n",
    "        word, idx = hypernyms_in_queue.pop(0)\n",
    "        processed_nodes.append(word)\n",
    "        if idx == level:\n",
    "            break\n",
    "        for syn in wn.synsets(word):\n",
    "            for hypernyms in syn.hypernyms():\n",
    "                for lemma in hypernyms.lemmas():\n",
    "                    all_hypernyms.append(lemma.name())\n",
    "                    if lemma.name() not in processed_nodes:\n",
    "                        hypernyms_in_queue.append((lemma.name(), idx + 1))\n",
    "    return set(all_hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hypernyms(word, level_in_depth = 0):\n",
    "    return set.union(\n",
    "        get_hypernyms_in_width_and_depth(word = word, level=level_in_depth),\n",
    "        get_hypernyms_to_root(word = word)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Isle_of_Man',\n",
       " 'Man',\n",
       " 'abstract_entity',\n",
       " 'abstraction',\n",
       " 'adult',\n",
       " 'adult_male',\n",
       " 'animal',\n",
       " 'animate_being',\n",
       " 'animate_thing',\n",
       " 'artefact',\n",
       " 'artifact',\n",
       " 'assistant',\n",
       " 'beast',\n",
       " 'being',\n",
       " 'body_servant',\n",
       " 'brute',\n",
       " 'cater',\n",
       " 'causal_agency',\n",
       " 'causal_agent',\n",
       " 'cause',\n",
       " 'chordate',\n",
       " 'craniate',\n",
       " 'creature',\n",
       " 'do_work',\n",
       " 'domestic_partner',\n",
       " 'dry_land',\n",
       " 'earth',\n",
       " 'entity',\n",
       " 'equipment',\n",
       " 'eutherian',\n",
       " 'eutherian_mammal',\n",
       " 'fauna',\n",
       " 'foot_soldier',\n",
       " 'game_equipment',\n",
       " 'gentleman',\n",
       " \"gentleman's_gentleman\",\n",
       " 'give',\n",
       " 'ground',\n",
       " 'group',\n",
       " 'grouping',\n",
       " 'grownup',\n",
       " 'help',\n",
       " 'helper',\n",
       " 'hominid',\n",
       " 'homo',\n",
       " 'human',\n",
       " 'human_being',\n",
       " 'human_beings',\n",
       " 'human_race',\n",
       " 'humanity',\n",
       " 'humankind',\n",
       " 'humans',\n",
       " 'individual',\n",
       " 'instrumentality',\n",
       " 'instrumentation',\n",
       " 'island',\n",
       " 'land',\n",
       " 'living_thing',\n",
       " 'lover',\n",
       " 'male',\n",
       " 'male_person',\n",
       " 'mammal',\n",
       " 'mammalian',\n",
       " 'man',\n",
       " 'mankind',\n",
       " 'military_man',\n",
       " 'military_personnel',\n",
       " 'mortal',\n",
       " 'object',\n",
       " 'organism',\n",
       " 'person',\n",
       " 'physical_entity',\n",
       " 'physical_object',\n",
       " 'piece',\n",
       " 'placental',\n",
       " 'placental_mammal',\n",
       " 'ply',\n",
       " 'primate',\n",
       " 'provide',\n",
       " 'retainer',\n",
       " 'servant',\n",
       " 'serviceman',\n",
       " 'significant_other',\n",
       " 'skilled_worker',\n",
       " 'skilled_workman',\n",
       " 'solid_ground',\n",
       " 'somebody',\n",
       " 'someone',\n",
       " 'soul',\n",
       " 'spousal_equivalent',\n",
       " 'spouse_equivalent',\n",
       " 'staff',\n",
       " 'subordinate',\n",
       " 'subsidiary',\n",
       " 'supply',\n",
       " 'supporter',\n",
       " 'terra_firma',\n",
       " 'trained_worker',\n",
       " 'transfer',\n",
       " 'underling',\n",
       " 'unit',\n",
       " 'valet',\n",
       " 'valet_de_chambre',\n",
       " 'vertebrate',\n",
       " 'whole',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'world'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_hypernyms('man', level_in_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "boy = wn.synsets('boy')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('male.n.02')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boy.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_if_words_have_parent_childre_relation(word1, word2):\n",
    "    word1_hypernyms = get_all_hypernyms(word1, level_in_depth=0)\n",
    "    word2_hypernyms = get_all_hypernyms(word2, level_in_depth=0)\n",
    "\n",
    "    if word1 in word2_hypernyms:\n",
    "        return 0\n",
    "    elif word2 in word1_hypernyms:\n",
    "        return 1\n",
    "    return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_words_have_parent_childre_relation('boy', 'male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_words_have_parent_childre_relation('girl', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_words_have_parent_childre_relation('man', 'men')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_if_words_have_parent_childre_relation('apple', 'fruit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract_entity',\n",
       " 'abstraction',\n",
       " 'attribute',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'badness',\n",
       " 'big',\n",
       " 'defective',\n",
       " 'entity',\n",
       " 'forged',\n",
       " 'high-risk',\n",
       " 'quality',\n",
       " 'regretful',\n",
       " 'risky',\n",
       " 'sorry',\n",
       " 'speculative',\n",
       " 'spoiled',\n",
       " 'spoilt',\n",
       " 'tough',\n",
       " 'uncollectible',\n",
       " 'unfit',\n",
       " 'unsound'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_hypernyms('bad', level_in_depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entailment_graph(verb):\n",
    "    all_entailments = set()\n",
    "    for syn in wn.synsets(verb):\n",
    "        for entailed_verb in syn.entailments():\n",
    "            for lemma in entailed_verb.lemmas():\n",
    "                all_entailments.add(lemma.name())\n",
    "    return [word.lower().replace('_', ' ') for word in all_entailments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solidify']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_entailment_graph('freeze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_meronyms(word):\n",
    "    all_meronyms = set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for meronym in syn.part_meronyms():\n",
    "            for lemma in meronym.lemmas():\n",
    "                all_meronyms.add(lemma.name())\n",
    "        for meronym in syn.substance_meronyms():\n",
    "            for lemma in meronym.lemmas():\n",
    "                all_meronyms.add(lemma.name())\n",
    "    return [word.lower().replace('_', ' ') for word in all_meronyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_holonyms(word):\n",
    "    all_holonyms = set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for meronym in syn.part_holonyms():\n",
    "            for lemma in meronym.lemmas():\n",
    "                all_holonyms.add(lemma.name())\n",
    "        for meronym in syn.substance_holonyms():\n",
    "            for lemma in meronym.lemmas():\n",
    "                all_holonyms.add(lemma.name())\n",
    "    return [word.lower().replace('_', ' ') for word in all_holonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['page']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_holonyms('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = sentences_with_amr_container[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company\\'s slogan \"Expect More. Pay Less.\"'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = obj[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = obj[1].graph_nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({'s': {'label': '\"s/slogan\"', 'shape': 'circle'}, 'c': {'label': '\"c/company\"', 'shape': 'circle'}, 'a': {'label': '\"a/and\"', 'shape': 'circle'}, 'e': {'label': '\"e/expect-01\"', 'shape': 'circle'}, 'm': {'label': '\"m/more\"', 'shape': 'circle'}, 'p': {'label': '\"p/pay-01\"', 'shape': 'circle'}, 'l': {'label': '\"l/less\"', 'shape': 'circle'}})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes(data= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 'slogan',\n",
       " 'c': 'company',\n",
       " 'a': 'and',\n",
       " 'e': 'expect',\n",
       " 'm': 'more',\n",
       " 'p': 'pay',\n",
       " 'l': 'less'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[1].label2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /nas/home/souratih/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /nas/home/souratih/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADV'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['quickly'], tagset = 'universal')[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for obj in sentences_with_amr_container:\n",
    "    a.append(obj[1].graph_nx.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 2, 22.53704705246079)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(a), min(a), sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22 * 21 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('general': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67db27fda20c3469892b63d0da2b9ea8ebefbe65ab5f07c46b1a9548ed206d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
