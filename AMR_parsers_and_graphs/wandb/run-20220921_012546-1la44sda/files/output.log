Number of training graphs: 1479
Number of test graphs: 370
"addmm_cuda" not implemented for 'Long'
Python 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.5.0 -- An enhanced Interactive Python. Type '?' for help.
RuntimeError('"addmm_cuda" not implemented for \'Long\'')
tensor([[ 0.0595,  0.1750,  0.7051,  ..., -0.4300,  0.0065,  0.2432],
        [ 0.1139,  0.0077,  0.2363,  ..., -0.5166,  0.2944, -0.2086],
        [ 0.1673,  0.5208, -0.2713,  ..., -0.3359, -0.2018, -0.3578],
        ...,
        [ 0.2170, -0.2472, -0.4867,  ..., -0.4104,  0.2585, -0.1097],
        [-0.4909,  0.3101,  0.2311,  ...,  0.7895,  0.0711,  0.4347],
        [ 0.1773,  0.3412, -0.0104,  ...,  0.3839, -0.1790,  0.4989]],
       device='cuda:0')
<function Tensor.type>
'torch.cuda.FloatTensor'
'torch.cuda.LongTensor'
tensor([[  0,   0,   1,  ..., 277, 277, 278],
        [  1,   2,   0,  ..., 276, 278, 277]], device='cuda:0')
tensor([[1]], device='cuda:0')
tensor([[2]], device='cuda:0')
tensor([[1]], device='cuda:0')
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
File ~/logical-fallacy-identification/AMR_parsers_and_graphs/gcn.py:53, in NormalNet.forward(self, data, batch)
     51 x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
---> 53 x = self.conv1(x, edge_index, edge_attr)
     55 x = F.relu(x)
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:176, in TransformerConv.forward(self, x, edge_index, edge_attr, return_attention_weights)
    175 # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa
--> 176 out = self.propagate(edge_index, query=query, key=key, value=value,
    177                      edge_attr=edge_attr, size=None)
    179 alpha = self._alpha
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:374, in MessagePassing.propagate(self, edge_index, size, **kwargs)
    373         msg_kwargs = res[0] if isinstance(res, tuple) else res
--> 374 out = self.message(**msg_kwargs)
    375 for hook in self._message_forward_hooks.values():
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:211, in TransformerConv.message(self, query_i, key_j, value_j, edge_attr, index, ptr, size_i)
    210 assert edge_attr is not None
--> 211 edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,
    212                                           self.out_channels)
    213 key_j += edge_attr
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:118, in Linear.forward(self, x)
    114 r"""
    115 Args:
    116     x (Tensor): The features.
    117 """
--> 118 return F.linear(x, self.weight, self.bias)
RuntimeError: "addmm_cuda" not implemented for 'Long'
During handling of the above exception, another exception occurred:
RuntimeError                              Traceback (most recent call last)
Cell In [11], line 1
----> 1 x @ x  # FAILS
RuntimeError: "addmm_cuda" not implemented for 'Long'
tensor([[1.]])
tensor([[1.]])
'torch.FloatTensor'
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
File ~/logical-fallacy-identification/AMR_parsers_and_graphs/gcn.py:53, in NormalNet.forward(self, data, batch)
     51 x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
---> 53 x = self.conv1(x, edge_index, edge_attr)
     55 x = F.relu(x)
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:176, in TransformerConv.forward(self, x, edge_index, edge_attr, return_attention_weights)
    175 # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa
--> 176 out = self.propagate(edge_index, query=query, key=key, value=value,
    177                      edge_attr=edge_attr, size=None)
    179 alpha = self._alpha
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:374, in MessagePassing.propagate(self, edge_index, size, **kwargs)
    373         msg_kwargs = res[0] if isinstance(res, tuple) else res
--> 374 out = self.message(**msg_kwargs)
    375 for hook in self._message_forward_hooks.values():
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:211, in TransformerConv.message(self, query_i, key_j, value_j, edge_attr, index, ptr, size_i)
    210 assert edge_attr is not None
--> 211 edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,
    212                                           self.out_channels)
    213 key_j += edge_attr
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:118, in Linear.forward(self, x)
    114 r"""
    115 Args:
    116     x (Tensor): The features.
    117 """
--> 118 return F.linear(x, self.weight, self.bias)
RuntimeError: "addmm_cuda" not implemented for 'Long'
During handling of the above exception, another exception occurred:
AttributeError                            Traceback (most recent call last)
Cell In [16], line 1
----> 1 x.LongTensor()
AttributeError: 'Tensor' object has no attribute 'LongTensor'
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
File ~/logical-fallacy-identification/AMR_parsers_and_graphs/gcn.py:53, in NormalNet.forward(self, data, batch)
     51 x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
---> 53 x = self.conv1(x, edge_index, edge_attr)
     55 x = F.relu(x)
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:176, in TransformerConv.forward(self, x, edge_index, edge_attr, return_attention_weights)
    175 # propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa
--> 176 out = self.propagate(edge_index, query=query, key=key, value=value,
    177                      edge_attr=edge_attr, size=None)
    179 alpha = self._alpha
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:374, in MessagePassing.propagate(self, edge_index, size, **kwargs)
    373         msg_kwargs = res[0] if isinstance(res, tuple) else res
--> 374 out = self.message(**msg_kwargs)
    375 for hook in self._message_forward_hooks.values():
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:211, in TransformerConv.message(self, query_i, key_j, value_j, edge_attr, index, ptr, size_i)
    210 assert edge_attr is not None
--> 211 edge_attr = self.lin_edge(edge_attr).view(-1, self.heads,
    212                                           self.out_channels)
    213 key_j += edge_attr
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:118, in Linear.forward(self, x)
    114 r"""
    115 Args:
    116     x (Tensor): The features.
    117 """
--> 118 return F.linear(x, self.weight, self.bias)
RuntimeError: "addmm_cuda" not implemented for 'Long'
During handling of the above exception, another exception occurred:
NameError                                 Traceback (most recent call last)
Cell In [17], line 1
----> 1 x.type(LongTensor)
NameError: name 'LongTensor' is not defined
tensor([[1]])
'torch.FloatTensor'
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
File ~/logical-fallacy-identification/AMR_parsers_and_graphs/gcn.py:246
    243 model = model.to(device)
    244 criterion = torch.nn.CrossEntropyLoss()
    245 optimizer = torch.optim.Adam(
--> 246     model.parameters(), lr=LEARNING_RATE, weight_decay=5e-4)
    248 for epoch in range(1, NUM_EPOCHS):
    249     train(model, train_data_loader, optimizer)
File ~/logical-fallacy-identification/AMR_parsers_and_graphs/gcn.py:173, in train(model, loader, optimizer)
    170 def train(model, loader, optimizer):
    171     model.train()
--> 173     for data in loader:  # Iterate in batches over the training dataset.
    174         data = data.to(device)
    175         out = model(data, data.batch)  # Perform a single forward pass.
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/module.py:1110, in Module._call_impl(self, *input, **kwargs)
   1106 # If we don't have any hooks, we want to skip the rest of the logic in
   1107 # this function, and just call forward.
   1108 if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1109         or _global_forward_hooks or _global_forward_pre_hooks):
-> 1110     return forward_call(*input, **kwargs)
   1111 # Do not call functions when jit is used
   1112 full_backward_hooks, non_full_backward_hooks = [], []
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/modules/loss.py:1163, in CrossEntropyLoss.forward(self, input, target)
   1162 def forward(self, input: Tensor, target: Tensor) -> Tensor:
-> 1163     return F.cross_entropy(input, target, weight=self.weight,
   1164                            ignore_index=self.ignore_index, reduction=self.reduction,
   1165                            label_smoothing=self.label_smoothing)
File ~/anaconda3/envs/general/lib/python3.10/site-packages/torch/nn/functional.py:2996, in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)
   2994 if size_average is not None or reduce is not None:
   2995     reduction = _Reduction.legacy_get_string(size_average, reduce)
-> 2996 return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (279) to match target batch_size (16).