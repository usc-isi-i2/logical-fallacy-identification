{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'faulty generalization': 'component fallacy', \n",
    "    'false causality': 'component fallacy', \n",
    "    'false dilemma': 'component fallacy', \n",
    "    'circular reasoning': 'component fallacy', \n",
    "    'fallacy of logic': 'component fallacy', \n",
    "    'fallacy of extension': 'component fallacy', \n",
    "    'fallacy of relevance': 'fallacy of relevance', \n",
    "    'ad populum': 'fallacy of relevance', \n",
    "    'ad hominem': 'fallacy of relevance', \n",
    "    'fallacy of credibility': 'fallacy of relevance', \n",
    "    'intentional': 'fallacy of relevance', \n",
    "    'equivocation': 'equivocation', \n",
    "    'appeal to emotion': 'fallacy of relevance'\n",
    "   \n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'fallacy of relevance': 0,\n",
    "    'component fallacy': 1, \n",
    "    'equivocation': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fallacy of logic',\n",
       " 'faulty generalization',\n",
       " 'circular reasoning',\n",
       " 'ad hominem',\n",
       " 'ad populum',\n",
       " 'false dilemma',\n",
       " 'false causality',\n",
       " 'intentional',\n",
       " 'fallacy of relevance',\n",
       " 'equivocation',\n",
       " 'fallacy of credibility',\n",
       " 'fallacy of extension']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dataset = pd.read_csv('../data/train_data/v1/edu_dev.csv') \n",
    "dataset = dataset[~(dataset['updated_label']=='appeal to emotion')]\n",
    "unique_labels = dataset['updated_label'].unique().tolist()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "train_dataset = pd.DataFrame()\n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/train_data/v2/'+label+'_train.csv') \n",
    "  train_dataset = pd.concat([train_dataset, dataset], ignore_index=True) \n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "test_dataset = pd.DataFrame() \n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/test_data/v2/'+label+'_test.csv') \n",
    "  test_dataset = pd.concat([test_dataset, dataset], ignore_index=True) \n",
    "test_dataset = test_dataset.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "dev_dataset = pd.DataFrame() \n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/dev_data/v2/'+label+'_dev.csv') \n",
    "  dev_dataset = pd.concat([dev_dataset, dataset], ignore_index=True) \n",
    "dev_dataset = dev_dataset.sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_article</th>\n",
       "      <th>updated_label</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>cleaner_prompt</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>text_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491</td>\n",
       "      <td>2107</td>\n",
       "      <td>What is The Texas Sharpshooter?</td>\n",
       "      <td>intentional</td>\n",
       "      <td>0</td>\n",
       "      <td>What is The Texas Sharpshooter? It is a high-p...</td>\n",
       "      <td>It is a high-powered.38 special revolver. Phe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2215</td>\n",
       "      <td>Speaker 1: Jesus was not really crucified.\\nSp...</td>\n",
       "      <td>circular reasoning</td>\n",
       "      <td>1</td>\n",
       "      <td>Speaker 1: Jesus was not really crucified. Spe...</td>\n",
       "      <td>Speaker 2: How do I know those are true? Spea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218</td>\n",
       "      <td>432</td>\n",
       "      <td>Last year, the city of Brookfield allocated mo...</td>\n",
       "      <td>false causality</td>\n",
       "      <td>0</td>\n",
       "      <td>Last year, the city of Brookfield allocated mo...</td>\n",
       "      <td>A: (1) The first sentence is, more or less, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>873</td>\n",
       "      <td>This type of propaganda implies that since EVE...</td>\n",
       "      <td>ad populum</td>\n",
       "      <td>1</td>\n",
       "      <td>This type of propaganda implies that since EVE...</td>\n",
       "      <td>Population: everyone else Belief: buying a pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0           491        2107   \n",
       "1            68        2215   \n",
       "2           218         432   \n",
       "3            92         873   \n",
       "\n",
       "                                      source_article       updated_label  \\\n",
       "0                    What is The Texas Sharpshooter?         intentional   \n",
       "1  Speaker 1: Jesus was not really crucified.\\nSp...  circular reasoning   \n",
       "2  Last year, the city of Brookfield allocated mo...     false causality   \n",
       "3  This type of propaganda implies that since EVE...          ad populum   \n",
       "\n",
       "   label                                       clean_prompt  \\\n",
       "0      0  What is The Texas Sharpshooter? It is a high-p...   \n",
       "1      1  Speaker 1: Jesus was not really crucified. Spe...   \n",
       "2      0  Last year, the city of Brookfield allocated mo...   \n",
       "3      1  This type of propaganda implies that since EVE...   \n",
       "\n",
       "                                      cleaner_prompt  Unnamed: 5  \\\n",
       "0   It is a high-powered.38 special revolver. Phe...         NaN   \n",
       "1   Speaker 2: How do I know those are true? Spea...         NaN   \n",
       "2   A: (1) The first sentence is, more or less, a...         NaN   \n",
       "3   Population: everyone else Belief: buying a pr...         NaN   \n",
       "\n",
       "  text_generated  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_article</th>\n",
       "      <th>updated_label</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>cleaner_prompt</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text_generated</th>\n",
       "      <th>updated_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>We can't believe what he says out of that ugly...</td>\n",
       "      <td>ad hominem</td>\n",
       "      <td>1</td>\n",
       "      <td>We can't believe what he says out of that ugly...</td>\n",
       "      <td>15.txt We can't believe what he says out of th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>Some of you have objected to the new test batt...</td>\n",
       "      <td>fallacy of relevance</td>\n",
       "      <td>0</td>\n",
       "      <td>Some of you have objected to the new test batt...</td>\n",
       "      <td>To this end, lbl04 will take effect tomorrow.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Audrey: I am a human being. I am not a cyborg ...</td>\n",
       "      <td>intentional</td>\n",
       "      <td>1</td>\n",
       "      <td>Audrey: I am a human being. I am not a cyborg ...</td>\n",
       "      <td>2: nooo a cyborg! cyborgs have emotions they n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Cat Stevens may be a successful and skilled mu...</td>\n",
       "      <td>ad hominem</td>\n",
       "      <td>0</td>\n",
       "      <td>Cat Stevens may be a successful and skilled mu...</td>\n",
       "      <td>21 Population: Cat Stevens Belief: extremists ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     source_article  \\\n",
       "0          32  We can't believe what he says out of that ugly...   \n",
       "1          45  Some of you have objected to the new test batt...   \n",
       "2           5  Audrey: I am a human being. I am not a cyborg ...   \n",
       "3          44  Cat Stevens may be a successful and skilled mu...   \n",
       "\n",
       "          updated_label  label  \\\n",
       "0            ad hominem      1   \n",
       "1  fallacy of relevance      0   \n",
       "2           intentional      1   \n",
       "3            ad hominem      0   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "0  We can't believe what he says out of that ugly...   \n",
       "1  Some of you have objected to the new test batt...   \n",
       "2  Audrey: I am a human being. I am not a cyborg ...   \n",
       "3  Cat Stevens may be a successful and skilled mu...   \n",
       "\n",
       "                                      cleaner_prompt  Unnamed: 0.1  \\\n",
       "0  15.txt We can't believe what he says out of th...           NaN   \n",
       "1     To this end, lbl04 will take effect tomorrow.            NaN   \n",
       "2  2: nooo a cyborg! cyborgs have emotions they n...           NaN   \n",
       "3  21 Population: Cat Stevens Belief: extremists ...           NaN   \n",
       "\n",
       "  text_generated updated_clean_text  \n",
       "0            NaN                NaN  \n",
       "1            NaN                NaN  \n",
       "2            NaN                NaN  \n",
       "3            NaN                NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset[train_dataset['updated_label'].isin(unique_labels)] \n",
    "test_dataset = test_dataset[test_dataset['updated_label'].isin(unique_labels)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels  = train_dataset['updated_label'].to_list()\n",
    "test_data_labels = test_dataset['updated_label'].to_list() \n",
    "dev_data_labels = dev_dataset['updated_label'].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_broad_classification, test_broad_classification, labels_test, labels_train, dev_broad_classification, labels_dev= [], [], [], [], [], [] \n",
    "\n",
    "for label in train_data_labels:\n",
    "    train_broad_classification.append(mappings[label])\n",
    "    labels_train.append(labels[mappings[label]])\n",
    "for label in test_data_labels:\n",
    "    test_broad_classification.append(mappings[label])\n",
    "    labels_test.append(labels[mappings[label]])\n",
    "for label in dev_data_labels:\n",
    "    dev_broad_classification.append(mappings[label])\n",
    "    labels_dev.append(labels[mappings[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['broad_class'] = train_broad_classification\n",
    "test_dataset['broad_class'] = test_broad_classification\n",
    "dev_dataset['broad_class'] = dev_broad_classification\n",
    "train_dataset['label'] = labels_train\n",
    "test_dataset['label'] = labels_test\n",
    "dev_dataset['label'] = labels_dev \n",
    "train_dataset.to_csv('../data/updated_edu_train_with_neg.csv', index=False)\n",
    "test_dataset.to_csv('../data/updated_edu_test_with_neg.csv', index=False) \n",
    "dev_dataset.to_csv('../data/updated_edu_dev_with_neg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = pd.DataFrame()\n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/train_data/v2/'+label+'_train.csv') \n",
    "  dataset = dataset[dataset['updated_label'].isin([label])] \n",
    "  train_dataset = pd.concat([train_dataset, dataset], ignore_index=True) \n",
    "train_dataset = train_dataset.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "test_dataset = pd.DataFrame() \n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/test_data/v2/'+label+'_test.csv') \n",
    "  dataset = dataset[dataset['updated_label'].isin([label])] \n",
    "  test_dataset = pd.concat([test_dataset, dataset], ignore_index=True) \n",
    "test_dataset = test_dataset.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "dev_dataset = pd.DataFrame() \n",
    "for label in unique_labels: \n",
    "  dataset = pd.read_csv('../data/dev_data/v2/'+label+'_dev.csv') \n",
    "  dataset = dataset[dataset['updated_label'].isin([label])] \n",
    "  dev_dataset = pd.concat([dev_dataset, dataset], ignore_index=True) \n",
    "dev_dataset = dev_dataset.sample(frac=1).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_labels  = train_dataset['updated_label'].to_list()\n",
    "test_data_labels = test_dataset['updated_label'].to_list() \n",
    "dev_data_labels = dev_dataset['updated_label'].to_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_broad_classification, test_broad_classification, labels_test, labels_train, dev_broad_classification, labels_dev= [], [], [], [], [], [] \n",
    "\n",
    "for label in train_data_labels:\n",
    "    train_broad_classification.append(mappings[label])\n",
    "    labels_train.append(labels[mappings[label]])\n",
    "for label in test_data_labels:\n",
    "    test_broad_classification.append(mappings[label])\n",
    "    labels_test.append(labels[mappings[label]])\n",
    "for label in dev_data_labels:\n",
    "    dev_broad_classification.append(mappings[label])\n",
    "    labels_dev.append(labels[mappings[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['broad_class'] = train_broad_classification\n",
    "test_dataset['broad_class'] = test_broad_classification\n",
    "dev_dataset['broad_class'] = dev_broad_classification\n",
    "train_dataset['label'] = labels_train\n",
    "test_dataset['label'] = labels_test\n",
    "dev_dataset['label'] = labels_dev \n",
    "train_dataset.to_csv('../data/updated_edu_train_without_neg.csv', index=False)\n",
    "test_dataset.to_csv('../data/updated_edu_test_without_neg.csv', index=False) \n",
    "dev_dataset.to_csv('../data/updated_edu_dev_without_neg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neuros')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4455a7d9a5fde2bdf2f7faf52cc6c3c081bc73476d60241f2f03234fa3a9b34e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
