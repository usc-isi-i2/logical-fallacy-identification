{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ad hominem': 0,\n",
       " 'ad populum': 1,\n",
       " 'fallacy of relevance': 2,\n",
       " 'faulty generalization': 3,\n",
       " 'circular reasoning': 4,\n",
       " 'false dilemma': 5,\n",
       " 'false causality': 6,\n",
       " 'fallacy of extension': 7,\n",
       " 'fallacy of logic': 8,\n",
       " 'intentional': 9,\n",
       " 'equivocation': 10,\n",
       " 'fallacy of credibility': 11}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "dataset = pd.read_csv('../data/broad_classifier/updated_edu_train_with_n.csv') \n",
    "unique_labels = dataset['updated_label'].unique().tolist()\n",
    "\n",
    "\n",
    "length_of_labels = len(unique_labels)\n",
    "mapping = dict()  \n",
    "for i in range(length_of_labels): \n",
    "  mapping[unique_labels[i]] = i \n",
    "\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('../data/broad_classifier/updated_edu_train_with_neg.csv') \n",
    "test_dataset = pd.read_csv('../data/broad_classifier/updated_edu_test_with_neg.csv') \n",
    "dev_dataset = pd.read_csv('../data/broad_classifier/updated_edu_dev_with_neg.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_class(updated_labels): \n",
    "  mapped_label = [] \n",
    "  for label in updated_labels: \n",
    "    mapped_label.append(mapping[label]) \n",
    "  return mapped_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mapped_label = map_class(train_dataset['updated_label'].to_list()) \n",
    "test_mapped_label = map_class(test_dataset['updated_label'].to_list()) \n",
    "dev_mapped_label = map_class(dev_dataset['updated_label'].to_list()) \n",
    "\n",
    "\n",
    "train_dataset['mapped_label'] = train_mapped_label \n",
    "test_dataset['mapped_label'] = test_mapped_label \n",
    "dev_dataset['mapped_label'] = dev_mapped_label\n",
    "\n",
    "train_dataset.to_csv('../data/broad_classifier/updated_edu_train_with_neg.csv', index=False) \n",
    "test_dataset.to_csv('../data/broad_classifier/updated_edu_test_with_neg.csv', index=False) \n",
    "dev_dataset.to_csv('../data/broad_classifier/updated_edu_dev_with_neg.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing dataset to fit the required format \n",
    "major_dataframe = pd.DataFrame() \n",
    "for label in unique_labels: \n",
    "    data = pd.read_csv('../data/train_data/v2/'+label+'_train.csv') \n",
    "    \n",
    "    updated_label_list = data['updated_label'].to_list()\n",
    "    origin = [] \n",
    "    for updated_label in updated_label_list: \n",
    "        if updated_label == label: \n",
    "            origin.append(label+':1') \n",
    "        else: \n",
    "            origin.append(label+':0') \n",
    "    data['origin'] = origin\n",
    "    major_dataframe = pd.concat([major_dataframe, data], ignore_index=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_article</th>\n",
       "      <th>updated_label</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>cleaner_prompt</th>\n",
       "      <th>origin</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>text_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>1280</td>\n",
       "      <td>Hybrid cars are like solar power, full of prom...</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>1</td>\n",
       "      <td>Hybrid cars are like solar power, full of prom...</td>\n",
       "      <td>Arg 1: hybrid cars are like solar power Arg 2...</td>\n",
       "      <td>fallacy of logic:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1308</td>\n",
       "      <td>Jack is a good athlete. Jack comes from Canada...</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>1</td>\n",
       "      <td>Jack is a good athlete. Jack comes from Canada...</td>\n",
       "      <td>Arg 1: Jack is a good athlete. Arg 2: all Can...</td>\n",
       "      <td>fallacy of logic:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>146</td>\n",
       "      <td>1599</td>\n",
       "      <td>“If you really loved me, you would buy me ever...</td>\n",
       "      <td>false dilemma</td>\n",
       "      <td>0</td>\n",
       "      <td>“If you really loved me, you would buy me ever...</td>\n",
       "      <td>\\nIf you really loved me, you would buy me eve...</td>\n",
       "      <td>fallacy of logic:0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1307</td>\n",
       "      <td>We should stop using hairspray because it is s...</td>\n",
       "      <td>fallacy of logic</td>\n",
       "      <td>1</td>\n",
       "      <td>We should stop using hairspray because it is s...</td>\n",
       "      <td>Arg 1: New York is snowing Arg 2: It is snowi...</td>\n",
       "      <td>fallacy of logic:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0           105        1280   \n",
       "1            20        1308   \n",
       "2           146        1599   \n",
       "3            14        1307   \n",
       "\n",
       "                                      source_article     updated_label  label  \\\n",
       "0  Hybrid cars are like solar power, full of prom...  fallacy of logic      1   \n",
       "1  Jack is a good athlete. Jack comes from Canada...  fallacy of logic      1   \n",
       "2  “If you really loved me, you would buy me ever...     false dilemma      0   \n",
       "3  We should stop using hairspray because it is s...  fallacy of logic      1   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "0  Hybrid cars are like solar power, full of prom...   \n",
       "1  Jack is a good athlete. Jack comes from Canada...   \n",
       "2  “If you really loved me, you would buy me ever...   \n",
       "3  We should stop using hairspray because it is s...   \n",
       "\n",
       "                                      cleaner_prompt              origin  \\\n",
       "0   Arg 1: hybrid cars are like solar power Arg 2...  fallacy of logic:1   \n",
       "1   Arg 1: Jack is a good athlete. Arg 2: all Can...  fallacy of logic:1   \n",
       "2  \\nIf you really loved me, you would buy me eve...  fallacy of logic:0   \n",
       "3   Arg 1: New York is snowing Arg 2: It is snowi...  fallacy of logic:1   \n",
       "\n",
       "   Unnamed: 5 text_generated  \n",
       "0         NaN            NaN  \n",
       "1         NaN            NaN  \n",
       "2         NaN            NaN  \n",
       "3         NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "major_dataframe.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_dataframe.to_csv('../data/train_data/combined_t5_prompts_train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neuros')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4455a7d9a5fde2bdf2f7faf52cc6c3c081bc73476d60241f2f03234fa3a9b34e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
