{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 50962169856\n",
      "Free memory: 1619460096\n",
      "Used memory: 49342709760\n"
     ]
    }
   ],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get memory info (444006400, 50962169856)\n",
      "Get number of devices available:  4\n",
      "Memory stats about which device is free: \n",
      "Device 0: b'Quadro RTX 8000', Memory : (0.87% free): 50962169856(total), 444006400 (free), 50518163456 (used)\n",
      "Device 1: b'Quadro RTX 8000', Memory : (6.16% free): 50962169856(total), 3138846720 (free), 47823323136 (used)\n",
      "Device 2: b'Quadro RTX 8000', Memory : (57.40% free): 50962169856(total), 29251534848 (free), 21710635008 (used)\n",
      "Device 3: b'Quadro RTX 8000', Memory : (99.99% free): 50962169856(total), 50958106624 (free), 4063232 (used)\n",
      "Current Device:   0\n"
     ]
    }
   ],
   "source": [
    "print(\"Get memory info\", torch.cuda.mem_get_info(device=None)) \n",
    "print(\"Get number of devices available: \", torch.cuda.device_count())\n",
    "\n",
    "print(\"Memory stats about which device is free: \")\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
    "for i in range(deviceCount):\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(\"Device {}: {}, Memory : ({:.2f}% free): {}(total), {} (free), {} (used)\".format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, info.total, info.free, info.used))\n",
    "\n",
    "nvidia_smi.nvmlShutdown()\n",
    "\n",
    "print(\"Current Device:  \", torch.cuda.current_device()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(3)\n",
    "torch.cuda.empty_cache() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicalFallacy(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataset\n",
    "        self.text = dataset.cleaner_prompt\n",
    "        self.targets = dataset.label\n",
    "        self.max_len = max_len\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "\n",
    "        return {\n",
    "            'sentence': text,\n",
    "            \n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "    \n",
    "        self.classifier = torch.nn.Linear(768, 3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop( train_loader, test_loader, label, test_data, epochs=5):\n",
    "  train_loss = []\n",
    "  test_loss = []\n",
    "  train_accuracy = []\n",
    "  test_accuracy = []\n",
    "  model = RobertaClass()\n",
    "  model.to(device)\n",
    "  loss_function = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "  test_answers = [[[],[]], [[],[]]]\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['Train', 'Test']:\n",
    "      if(phase == 'Train'):\n",
    "        model.train()\n",
    "        loader = train_loader\n",
    "      else:\n",
    "        model.eval()\n",
    "        loader = test_loader  \n",
    "      epoch_loss = 0\n",
    "      epoch_acc = 0\n",
    "      len(loader)\n",
    "      for steps, data in tqdm(enumerate(loader, 0)):\n",
    "        sentence = data['sentence']\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "      \n",
    "        outputs = model.forward(ids, mask, token_type_ids)\n",
    "\n",
    "        loss = loss_function(outputs, targets)        \n",
    "        \n",
    "        epoch_loss += loss.detach()\n",
    "        _, max_indices = torch.max(outputs.data, dim=1)\n",
    "        bath_acc = (max_indices==targets).sum().item()/targets.size(0)\n",
    "        epoch_acc += bath_acc\n",
    "\n",
    "        if (phase == 'Train'):\n",
    "          train_loss.append(loss.detach()) \n",
    "          train_accuracy.append(bath_acc)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        else:\n",
    "          test_loss.append(loss.detach()) \n",
    "          test_accuracy.append(bath_acc)\n",
    "         \n",
    "\n",
    "      print(f\"{phase} Loss: {epoch_loss/steps}\")\n",
    "      print(f\"{phase} Accuracy: {epoch_acc/steps}\")\n",
    "  \n",
    "  torch.save(model, '../models/broad_classifiers/broad_classifier_trained_roberta_prompt_balanced.pt')\n",
    "  return (train_loss, test_loss, train_accuracy, test_accuracy, test_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_code():\n",
    "    train_df = pd.read_csv('../data/broad_classifier/updated_edu_train_balanced.csv')\n",
    "    test_df = pd.read_csv('../data/broad_classifier/updated_edu_dev_balanced.csv')\n",
    "    \n",
    "\n",
    "    train_set = LogicalFallacy(train_df, tokenizer, MAX_LEN)\n",
    "    test_set = LogicalFallacy(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "    train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "    test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "    train_loader = DataLoader(train_set, **train_params)\n",
    "    test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "    \n",
    "    value = train_loop( train_loader, test_loader, 'xxxx',  test_df['updated_label'], epochs=5)\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "544it [01:18,  6.91it/s]\n",
      "4it [00:00, 38.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6746110320091248\n",
      "Train Accuracy: 0.6579189686924494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:05, 38.96it/s]\n",
      "1it [00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0032083988189697\n",
      "Test Accuracy: 0.6915849673202615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [01:19,  6.86it/s]\n",
      "5it [00:00, 41.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.236724853515625\n",
      "Train Accuracy: 0.9044659300184162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:05, 39.45it/s]\n",
      "1it [00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3126716613769531\n",
      "Test Accuracy: 0.6597222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [01:19,  6.84it/s]\n",
      "4it [00:00, 38.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08520865440368652\n",
      "Train Accuracy: 0.9726058931860037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:05, 39.37it/s]\n",
      "1it [00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.344785213470459\n",
      "Test Accuracy: 0.693218954248366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [01:19,  6.81it/s]\n",
      "4it [00:00, 37.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03676893189549446\n",
      "Train Accuracy: 0.9912523020257827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:05, 39.05it/s]\n",
      "1it [00:00,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.661028504371643\n",
      "Test Accuracy: 0.6699346405228758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [01:19,  6.84it/s]\n",
      "5it [00:00, 40.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.033795859664678574\n",
      "Train Accuracy: 0.9912523020257827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "205it [00:05, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7121220827102661\n",
      "Test Accuracy: 0.7005718954248366\n"
     ]
    }
   ],
   "source": [
    "vals = driver_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neuros')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4455a7d9a5fde2bdf2f7faf52cc6c3c081bc73476d60241f2f03234fa3a9b34e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
