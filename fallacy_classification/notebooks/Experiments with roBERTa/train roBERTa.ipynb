{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 50962169856\n",
      "Free memory: 39158480896\n",
      "Used memory: 11803688960\n"
     ]
    }
   ],
   "source": [
    "import nvidia_smi\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(\"Total memory:\", info.total)\n",
    "\n",
    "\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n",
    "\n",
    "nvidia_smi.nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get memory info (37983027200, 50962169856)\n",
      "Get number of devices available:  3\n",
      "Memory stats about which device is free: \n",
      "Device 0: b'Quadro RTX 8000', Memory : (74.53% free): 50962169856(total), 37983027200 (free), 12979142656 (used)\n",
      "Device 1: b'Quadro RTX 8000', Memory : (99.99% free): 50962169856(total), 50958106624 (free), 4063232 (used)\n",
      "Device 2: b'Quadro RTX 8000', Memory : (5.26% free): 50962169856(total), 2678521856 (free), 48283648000 (used)\n",
      "Current Device:   0\n",
      "Most free device:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Get memory info\", torch.cuda.mem_get_info(device=None)) \n",
    "print(\"Get number of devices available: \", torch.cuda.device_count())\n",
    "\n",
    "print(\"Memory stats about which device is free: \")\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
    "most_free = 0 \n",
    "device_num = 0\n",
    "for i in range(deviceCount):\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(\"Device {}: {}, Memory : ({:.2f}% free): {}(total), {} (free), {} (used)\".format(i, nvidia_smi.nvmlDeviceGetName(handle), 100*info.free/info.total, info.total, info.free, info.used))\n",
    "    if 100*info.free/info.total > most_free:\n",
    "        most_free = 100*info.free/info.total \n",
    "        device_num = i \n",
    "\n",
    "nvidia_smi.nvmlShutdown()\n",
    "\n",
    "print(\"Current Device:  \", torch.cuda.current_device()) \n",
    "print(\"Most free device: \", device_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = [\n",
    "'circular reasoning', \n",
    "'false dilemma',\n",
    "'ad populum',\n",
    "'ad hominem', \n",
    "'fallacy of logic', \n",
    "'equivocation', \n",
    "'fallacy of extension', \n",
    "'fallacy of relevance', \n",
    "'fallacy of credibility', \n",
    "'intentional', \n",
    "'faulty generalization', \n",
    "    \n",
    "'false causality'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LEN = 256\n",
    "\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicalFallacy(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataset\n",
    "        self.text = dataset.source_article\n",
    "        self.targets = dataset.label\n",
    "        self.max_len = max_len\n",
    "        self.original_label = dataset.updated_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "\n",
    "        return {\n",
    "            'sentence': text,\n",
    "            \n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        \n",
    "        self.classifier = torch.nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_loop( train_loader, test_loader, label, test_data, epochs=5):\n",
    "  train_loss = []\n",
    "  test_loss = []\n",
    "  train_accuracy = []\n",
    "  test_accuracy = []\n",
    "  model = RobertaClass()\n",
    "  model.to(device)\n",
    "  loss_function = torch.nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "  test_answers = [[[],[]], [[],[]]]\n",
    "  for epoch in range(epochs):\n",
    "    for phase in ['Train', 'Test']:\n",
    "      if(phase == 'Train'):\n",
    "        model.train()\n",
    "        loader = train_loader\n",
    "      else:\n",
    "        model.eval()\n",
    "        loader = test_loader  \n",
    "      epoch_loss = 0\n",
    "      epoch_acc = 0\n",
    "      len(loader)\n",
    "      for steps, data in tqdm(enumerate(loader, 0)):\n",
    "        sentence = data['sentence']\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "      \n",
    "        outputs = model.forward(ids, mask, token_type_ids)\n",
    "\n",
    "        loss = loss_function(outputs, targets)        \n",
    "        \n",
    "        epoch_loss += loss.detach()\n",
    "        _, max_indices = torch.max(outputs.data, dim=1)\n",
    "        bath_acc = (max_indices==targets).sum().item()/targets.size(0)\n",
    "        epoch_acc += bath_acc\n",
    "\n",
    "        if (phase == 'Train'):\n",
    "          train_loss.append(loss.detach()) \n",
    "          train_accuracy.append(bath_acc)\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        else:\n",
    "          test_loss.append(loss.detach()) \n",
    "          test_accuracy.append(bath_acc)\n",
    "          if epoch == epochs-1:\n",
    "            for i in range(len(targets)):\n",
    "              test_answers[targets[i].item()][max_indices[i].item()].append([\n",
    "                                                                  sentence[i], \n",
    "                                                                  targets[i].item(), \n",
    "                                                                  max_indices[i].item()])\n",
    "\n",
    "      print(f\"{phase} Loss: {epoch_loss/steps}\")\n",
    "      print(f\"{phase} Accuracy: {epoch_acc/steps}\")\n",
    "  \n",
    "  torch.save(model, '../models/v3/articles/'+label+'_trained_roberta.pt')\n",
    "  return test_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_code(label, train_df, test_df):\n",
    "   \n",
    "    ars = [] \n",
    "    #for val in train_df['label']: \n",
    "        #if val=='0': \n",
    "            #ars.append(0) \n",
    "        #else: \n",
    "            \n",
    "            #ars.append(1) \n",
    "    #train_df['label'] = ars\n",
    "    train_set = LogicalFallacy(train_df, tokenizer, MAX_LEN)\n",
    "    test_set = LogicalFallacy(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "    train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "    test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "    train_loader = DataLoader(train_set, **train_params)\n",
    "    test_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "    \n",
    "    value = train_loop( train_loader, test_loader, label,  test_df['updated_label'], epochs=4)\n",
    "    return value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/vishnu/neurosymbolic-argumentation/notebooks/train roBERTa.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/train_data/v2/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mlabel\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_train.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000010vscode-remote?line=5'>6</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/dev_data/v2/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mlabel\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_dev.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m test_answers_list\u001b[39m.\u001b[39mappend(driver_code(label, train_df, test_df))\n",
      "\u001b[1;32m/data/vishnu/neurosymbolic-argumentation/notebooks/train roBERTa.ipynb Cell 10'\u001b[0m in \u001b[0;36mdriver_code\u001b[0;34m(label, train_df, test_df)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000009vscode-remote?line=22'>23</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_set, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000009vscode-remote?line=23'>24</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(test_set, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtest_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000009vscode-remote?line=26'>27</a>\u001b[0m value \u001b[39m=\u001b[39m train_loop( train_loader, test_loader, label,  test_df[\u001b[39m'\u001b[39;49m\u001b[39mupdated_label\u001b[39;49m\u001b[39m'\u001b[39;49m], epochs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000009vscode-remote?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[1;32m/data/vishnu/neurosymbolic-argumentation/notebooks/train roBERTa.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(train_loader, test_loader, label, test_data, epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m test_accuracy \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m RobertaClass()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000008vscode-remote?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000008vscode-remote?line=7'>8</a>\u001b[0m loss_function \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bckg08.isi.edu/data/vishnu/neurosymbolic-argumentation/notebooks/train%20roBERTa.ipynb#ch0000008vscode-remote?line=8'>9</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(params \u001b[39m=\u001b[39m  model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mLEARNING_RATE)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=894'>895</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=895'>896</a>\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=896'>897</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=898'>899</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=568'>569</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=569'>570</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=571'>572</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=572'>573</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=573'>574</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=574'>575</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=568'>569</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=569'>570</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=571'>572</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=572'>573</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=573'>574</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=574'>575</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=568'>569</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=569'>570</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=571'>572</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=572'>573</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=573'>574</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=574'>575</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=589'>590</a>\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=590'>591</a>\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=591'>592</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=592'>593</a>\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=593'>594</a>\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=594'>595</a>\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=893'>894</a>\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=894'>895</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=895'>896</a>\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> <a href='file:///nas/home/vprasann/anaconda3/envs/neuros/lib/python3.8/site-packages/torch/nn/modules/module.py?line=896'>897</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "test_answers_list = []\n",
    "for label in unique_labels:\n",
    "    \n",
    "    train_df = pd.read_csv('../data/train_data/v2/'+label+'_train.csv')\n",
    "\n",
    "    test_df = pd.read_csv('../data/dev_data/v2/'+label+'_dev.csv')\n",
    "    test_answers_list.append(driver_code(label, train_df, test_df)) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def truncate(f, n):\n",
    "    \n",
    "    return math.floor(f * 10 ** n) / 10 ** n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp_list, tn_list, fp_list, fn_list = [], [], [], [] \n",
    "accuracy_list, precision_list, recall_list = [], [], [] \n",
    "for i in range(len(unique_labels)):\n",
    "    test_df = pd.read_csv('../data/test_data/v2/'+label+'_test.csv')\n",
    "    len_num = len(test_df)\n",
    "    if len_num<=0:\n",
    "        len_num = 1\n",
    "    tp=len(test_answers_list[i][1][1])/len_num\n",
    "    fn=len(test_answers_list[i][1][0])/len_num\n",
    "    fp=len(test_answers_list[i][0][1])/len_num\n",
    "    tn=len(test_answers_list[i][0][0])/len_num\n",
    "\n",
    "\n",
    "    array_matrix = [[tp,tn], \n",
    "                    [fp,fn]]\n",
    "    df_cm = pd.DataFrame(array_matrix, index = ['T', 'F'],\n",
    "                    columns = ['P', 'N'])\n",
    "    plt.figure(figsize = (5,5))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "    precision = truncate( tp / (tp + fp), 3) \n",
    "    recall = truncate( tp/ (tp + fn), 3)\n",
    "    accuracy =truncate( tp+tn/(tp+tn+fp+fn), 3) \n",
    "\n",
    "    tp_list.append(truncate(tp,3)) \n",
    "    tn_list.append(truncate(tn, 3)) \n",
    "    fp_list.append(truncate(fp,3)) \n",
    "    fn_list.append(truncate(fn, 3))\n",
    "    accuracy_list.append(accuracy) \n",
    "    recall_list.append(recall) \n",
    "    precision_list.append(precision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {\n",
    "    'fallacy class': unique_labels, \n",
    "    'accuracy': accuracy_list,\n",
    "    'precision': precision_list, \n",
    "    'recall': recall_list, \n",
    "    'TP': tp_list, \n",
    "    'TN': tn_list,\n",
    "    'FP':fp_list, \n",
    "    'FN':fn_list, \n",
    "    #'Classes for False Positive:': extract_classes\n",
    "}\n",
    "df = pd.DataFrame.from_dict(dictionary) \n",
    "df.to_csv (r'../results/v2/intentional_sentece_prompt.csv', index = False, header=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.read_csv('../data/dev_data/v2/equivocation_dev.csv') \n",
    "s['label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4455a7d9a5fde2bdf2f7faf52cc6c3c081bc73476d60241f2f03234fa3a9b34e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('neuros')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
